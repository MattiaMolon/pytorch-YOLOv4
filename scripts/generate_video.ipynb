{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd04e0858098b971b6a13f714418cf0db8978f6878bdac17da64902c6b3977ed784",
   "display_name": "Python 3.8.5  ('.master_thesis_venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "4e0858098b971b6a13f714418cf0db8978f6878bdac17da64902c6b3977ed784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from tool.darknet2pytorch import Darknet\n",
    "import cv2\n",
    "import imageio\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from cfg.train.cfg_yolov4_BEV_area_nuScenes import Cfg as cfg\n",
    "\n",
    "# check for cuda\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# params\n",
    "cfg.weights = \"../checkpoints/area_focalloss_alpha50_gamma6_rows50_sgd_nomax/Yolo_BEV_area_nuScenes_epoch39__BESTSOFAR.pth\"\n",
    "cfg.dataset_dir = \"../../data/nuScenes/\"\n",
    "cfg.cfgfile = \"../cfg/model/yolov4_BEV_area_nuScenes.cfg\"\n",
    "\n",
    "# read scenes\n",
    "scenes = []\n",
    "with open(os.path.join(cfg.dataset_dir, \"splits\", \"test_scenes.txt\")) as f:\n",
    "    for l in f:\n",
    "        scenes.append(l.strip())\n",
    "\n",
    "# nuscenes\n",
    "version = \"v1.0-trainval\"\n",
    "nusc = NuScenes(version=version, dataroot=cfg.dataset_dir, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# remove \"model\" bug from parallel GPU training\n",
    "state_dict = torch.load(cfg.weights, map_location=torch.device(device))\n",
    "if \"module\" in list(state_dict.keys())[0]:\n",
    "    state_dict_tmp = {}\n",
    "    for k in state_dict.keys():\n",
    "        state_dict_tmp[k[7:]] = state_dict[k]\n",
    "    state_dict = state_dict_tmp\n",
    "\n",
    "# model\n",
    "m = Darknet(cfg.cfgfile, model_type=\"BEV_dist\")\n",
    "m.load_state_dict(state_dict)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    m = torch.nn.DataParallel(m)\n",
    "m.to(device)\n",
    "m.eval()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_id = 2\n",
    "sensor = \"CAM_FRONT_RIGHT\"\n",
    "thr = 0.60\n",
    "# params\n",
    "pred_times = []\n",
    "preds = []\n",
    "frames = []\n",
    "\n",
    "# get current scene\n",
    "scene = nusc.get(\"scene\", scenes[scene_id])\n",
    "current_token = scene[\"first_sample_token\"]\n",
    "n_frames = scene[\"nbr_samples\"]\n",
    "while current_token != \"\":\n",
    "\n",
    "    # get sample\n",
    "    sample = nusc.get(\"sample\", current_token)\n",
    "    current_token = sample[\"next\"]\n",
    "\n",
    "    # get image path\n",
    "    img_path = nusc.get_sample_data(sample[\"data\"][sensor])[0]\n",
    "    \n",
    "    # prepare img for network\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    frame = img.copy()\n",
    "    img = img.astype(float) / 255.0\n",
    "    img = cv2.resize(img, (cfg.width, cfg.height))\n",
    "    img = img.transpose(2,0,1)\n",
    "    input = torch.Tensor(img).unsqueeze(0).to(device)\n",
    "\n",
    "    # predict\n",
    "    start = time.time()\n",
    "    pred = m(input)\n",
    "    end = time.time()\n",
    "\n",
    "    # prepare pred and frame\n",
    "    pred = pred.squeeze().detach().cpu().numpy().transpose()\n",
    "    pred = np.where(pred >= thr, pred, 0.0)\n",
    "    pred = np.flipud(pred)\n",
    "    frame = cv2.resize(frame, (cfg.width, cfg.height))\n",
    "    \n",
    "    # collect data\n",
    "    pred_times.append(end - start)\n",
    "    preds.append(pred)\n",
    "    frames.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save preds momentarily to keep plt colormap\n",
    "os.makedirs(\"preds_tmp\")\n",
    "new_preds = []\n",
    "for i,p in enumerate(preds):\n",
    "     plt.imsave(f\"preds_tmp/{i}.png\", p)\n",
    "     new_preds.append(plt.imread(f\"preds_tmp/{i}.png\")[..., :3])\n",
    "shutil.rmtree(\"preds_tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put images side by side\n",
    "sequence = []\n",
    "for f, p in zip(frames, new_preds):\n",
    "\n",
    "    # rescaling predictions\n",
    "    if (p.shape[0] * 2 < f.shape[0]):\n",
    "        p = cv2.resize(p, (p.shape[1]*2, p.shape[0]*2))\n",
    "\n",
    "    # compute padding values\n",
    "    pad_tb = (f.shape[0] - p.shape[0]) // 2\n",
    "    odd_tb = False if pad_tb % 2 == 0 else True\n",
    "\n",
    "    # apply paddings\n",
    "    pad_top = np.zeros((pad_tb, p.shape[1], 3))\n",
    "    pad_bot = np.zeros((pad_tb - 1, p.shape[1], 3)) if odd_tb else pad_top.copy()\n",
    "    p = np.vstack((pad_top, p, pad_bot))\n",
    "\n",
    "    pad_lr = np.zeros((p.shape[0], 5, 3))\n",
    "    p = np.hstack((pad_lr, p, pad_lr))\n",
    "\n",
    "    # create frames\n",
    "    p *= 255\n",
    "    f, p= f.astype(\"uint8\"), p.astype(\"uint8\")\n",
    "    collage = np.hstack((f, p))\n",
    "    sequence.append(collage)\n",
    "\n",
    "imageio.mimsave(f\"{scenes[scene_id]}_{sensor}.gif\", sequence, duration=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.2131154247204345"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "t = np.array(pred_times)\n",
    "1 / t.mean()"
   ]
  }
 ]
}